{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sparkmagic.magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eae52543cf84c4bac6c2c6e1fadcc3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MagicsControllerWidget(children=(Tab(children=(ManageSessionWidget(children=(HTML(value='<br/>'), HTML(value='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added endpoint http://ec2-174-129-53-123.compute-1.amazonaws.com:8998/\n",
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>3</td><td>application_1609005315067_0005</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-18-127.ec2.internal:20888/proxy/application_1609005315067_0005/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-18-35.ec2.internal:8042/node/containerlogs/container_1609005315067_0005_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "%manage_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "Path does not exist: hdfs://ip-172-31-18-127.ec2.internal:8020/data/1-data_acquisition/1-members.output.zip;\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py\", line 535, in csv\n",
      "    return self._df(self._jreader.csv(self._spark._sc._jvm.PythonUtils.toSeq(path)))\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1305, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\", line 137, in deco\n",
      "    raise_from(converted)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "pyspark.sql.utils.AnalysisException: Path does not exist: hdfs://ip-172-31-18-127.ec2.internal:8020/data/1-data_acquisition/1-members.output.zip;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "    \n",
    "members = spark.read.csv(f'../../data/1-data_acquisition/1-members.output.zip', header=True)\n",
    "trans = spark.read.csv(f'../../data/1-data_acquisition/1-transactions.output.zip', header=True)\n",
    "logs = spark.read.csv(f'../../data/1-data_acquisition/1-logs.output.zip', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%scala` not found.\n"
     ]
    }
   ],
   "source": [
    "def label_customer(customer_id, customer_transactions, prediction_date, churn_days, \n",
    "                   lead_time = 1, prediction_window = 1, return_trans = False):\n",
    "    \"\"\"\n",
    "    Make label times for a single customer. Returns a dataframe of labels with times, the binary label, \n",
    "    and the number of days until the next churn.\n",
    "       \n",
    "    Params\n",
    "    --------\n",
    "        customer_id (str): unique id for the customer\n",
    "        customer_transactions (dataframe): transactions dataframe for the customer\n",
    "        prediction_date (str): time at which predictions are made. Either \"MS\" for the first of the month\n",
    "                               or \"SMS\" for the first and fifteenth of each month \n",
    "        churn_days (int): integer number of days without an active membership required for a churn. A churn is\n",
    "                          defined by exceeding this number of days without an active membership.\n",
    "        lead_time (int): number of periods in advance to make predictions for. Defaults to 1 (preditions for one offset)\n",
    "        prediction_window(int): number of periods over which to consider churn. Defaults to 1.\n",
    "        return_trans (boolean): whether or not to return the transactions for analysis. Defaults to False.\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        label_times (dataframe): a table of customer id, the cutoff times at the specified frequency, the \n",
    "                                 label for each cutoff time, the number of days until the next churn for each\n",
    "                                 cutoff time, and the date on which the churn itself occurred.\n",
    "        transactions (dataframe): [optional] dataframe of customer transactions if return_trans = True. Useful\n",
    "                                  for making sure that the function performed as expected\n",
    "    \n",
    "       \"\"\"\n",
    "    \n",
    "    assert(prediction_date in ['MS', 'SMS']), \"Prediction day must be either 'MS' or 'SMS'\"\n",
    "    assert(customer_transactions['msno'].unique() == [customer_id]), \"Transactions must be for only customer\"\n",
    "    \n",
    "    # Don't modify original\n",
    "    transactions = customer_transactions.copy()\n",
    "    \n",
    "    # Make sure to sort chronalogically\n",
    "    transactions.sort_values(['transaction_date', 'membership_expire_date'], inplace = True)\n",
    "    \n",
    "    # Create next transaction date by shifting back one transaction\n",
    "    transactions['next_transaction_date'] = transactions['transaction_date'].shift(-1)\n",
    "    \n",
    "    # Find number of days between membership expiration and next transaction\n",
    "    transactions['difference_days'] = (transactions['next_transaction_date'] - \n",
    "                                       transactions['membership_expire_date']).\\\n",
    "                                       dt.total_seconds() / (3600 * 24)\n",
    "    \n",
    "    # Determine which transactions are associated with a churn\n",
    "    transactions['churn'] = transactions['difference_days'] > churn_days\n",
    "    \n",
    "    # Find date of each churn\n",
    "    transactions.loc[transactions['churn'] == True, \n",
    "                     'churn_date'] = transactions.loc[transactions['churn'] == True, \n",
    "                                                      'membership_expire_date'] + pd.Timedelta(churn_days + 1, 'd')\n",
    "    \n",
    "    # Range for cutoff times is from first to (last + 1 month) transaction\n",
    "    first_transaction = transactions['transaction_date'].min()\n",
    "    last_transaction = transactions['transaction_date'].max()\n",
    "    start_date = pd.datetime(first_transaction.year, first_transaction.month, 1)\n",
    "    \n",
    "    # Handle December\n",
    "    if last_transaction.month == 12:\n",
    "        end_date = pd.datetime(last_transaction.year + 1, 1, 1)\n",
    "    else:\n",
    "        end_date = pd.datetime(last_transaction.year, last_transaction.month + 1, 1)\n",
    "    \n",
    "    # Make label times dataframe with cutoff times corresponding to prediction date\n",
    "    label_times = pd.DataFrame({'cutoff_time': pd.date_range(start_date, end_date, freq = prediction_date),\n",
    "                                'msno': customer_id\n",
    "                               })\n",
    "    \n",
    "    # Use the lead time and prediction window parameters to establish the prediction window \n",
    "    # Prediction window is for each cutoff time\n",
    "    label_times['prediction_window_start'] = label_times['cutoff_time'].shift(-lead_time)\n",
    "    label_times['prediction_window_end'] = label_times['cutoff_time'].shift(-(lead_time + prediction_window))\n",
    "    \n",
    "    previous_churn_date = None\n",
    "\n",
    "    # Iterate through every cutoff time\n",
    "    for i, row in label_times.iterrows():\n",
    "        \n",
    "        # Default values if unknown\n",
    "        churn_date = pd.NaT\n",
    "        label = np.nan\n",
    "        # Find the window start and end\n",
    "        window_start = row['prediction_window_start']\n",
    "        window_end = row['prediction_window_end']\n",
    "        # Determine if there were any churns during the prediction window\n",
    "        churns = transactions.loc[(transactions['churn_date'] >= window_start) & \n",
    "                                  (transactions['churn_date'] < window_end), 'churn_date']\n",
    "\n",
    "        # Positive label if there was a churn during window\n",
    "        if not churns.empty:\n",
    "            label = 1\n",
    "            churn_date = churns.values[0]\n",
    "\n",
    "            # Find number of days until next churn by \n",
    "            # subsetting to cutoff times before current churn and after previous churns\n",
    "            if not previous_churn_date:\n",
    "                before_idx = label_times.loc[(label_times['cutoff_time'] <= churn_date)].index\n",
    "            else:\n",
    "                before_idx = label_times.loc[(label_times['cutoff_time'] <= churn_date) & \n",
    "                                             (label_times['cutoff_time'] > previous_churn_date)].index\n",
    "\n",
    "            # Calculate days to next churn for cutoff times before current churn\n",
    "            label_times.loc[before_idx, 'days_to_churn'] = (churn_date - label_times.loc[before_idx, \n",
    "                                                                                         'cutoff_time']).\\\n",
    "                                                            dt.total_seconds() / (3600 * 24)\n",
    "            previous_churn_date = churn_date\n",
    "        # No churns, but need to determine if an active member\n",
    "        else:\n",
    "            # Find transactions before the end of the window that were not cancelled\n",
    "            transactions_before = transactions.loc[(transactions['transaction_date'] < window_end) & \n",
    "                                                   (transactions['is_cancel'] == False)].copy()\n",
    "            # If the membership expiration date for this membership is after the window start, the custom has not churned\n",
    "            if np.any(transactions_before['membership_expire_date'] >= window_start):\n",
    "                label = 0\n",
    "\n",
    "        # Assign values\n",
    "        label_times.loc[i, 'label'] = label\n",
    "        label_times.loc[i, 'churn_date'] = churn_date\n",
    "        \n",
    "        # Handle case with no churns\n",
    "        if not np.any(label_times['label'] == 1):\n",
    "            label_times['days_to_churn'] = np.nan\n",
    "            label_times['churn_date'] = pd.NaT\n",
    "        \n",
    "    if return_trans:\n",
    "        return label_times.drop(columns = ['msno']), transactions\n",
    "    \n",
    "    return label_times[['msno', 'cutoff_time', 'label', 'days_to_churn', 'churn_date']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_label_times(transactions, prediction_date, churn_days, \n",
    "                   lead_time = 1, prediction_window = 1,):\n",
    "    \"\"\"\n",
    "    Make labels for an entire series of transactions. \n",
    "    \n",
    "    Params\n",
    "    --------\n",
    "        transactions (dataframe): table of customer transactions\n",
    "        prediction_date (str): time at which predictions are made. Either \"MS\" for the first of the month\n",
    "                               or \"SMS\" for the first and fifteenth of each month \n",
    "        churn_days (int): integer number of days without an active membership required for a churn. A churn is\n",
    "                          defined by exceeding this number of days without an active membership.\n",
    "        lead_time (int): number of periods in advance to make predictions for. Defaults to 1 (preditions for one offset)\n",
    "        prediction_window(int): number of periods over which to consider churn. Defaults to 1.\n",
    "    Return\n",
    "    --------\n",
    "        label_times (dataframe): a table with customer ids, cutoff times, binary label, regression label, \n",
    "                                 and date of churn. This table can then be used for feature engineering.\n",
    "    \"\"\"\n",
    "    \n",
    "    label_times = []\n",
    "    transactions = transactions.sort_values(['msno', 'transaction_date'])\n",
    "    \n",
    "    # Iterate through each customer and find labels\n",
    "    for customer_id, customer_transactions in transactions.groupby('msno'):\n",
    "        lt_cust = label_customer(customer_id, customer_transactions,\n",
    "                                                   prediction_date, churn_days, \n",
    "                                                   lead_time, prediction_window)\n",
    "        \n",
    "        label_times.append(lt_cust)\n",
    "        \n",
    "    # Concatenate into a single dataframe\n",
    "    return pd.concat(label_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_times = make_label_times(trans, prediction_date = 'MS', churn_days = 31,\n",
    "                               lead_time = 1, prediction_window = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
