{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Feature Selection\n",
    "\n",
    "##### Description\n",
    "\n",
    "Select top features based upon correlation matrix.\n",
    "\n",
    "##### Notebook Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connect Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext sparkmagic.magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd668d6d1539450bac525f523607d8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MagicsControllerWidget(children=(Tab(children=(ManageSessionWidget(children=(HTML(value='<br/>'), HTML(value='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added endpoint http://ec2-54-91-225-25.compute-1.amazonaws.com:8998/\n",
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1</td><td>application_1612113777859_0002</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-26-202.ec2.internal:20888/proxy/application_1612113777859_0002/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-17-27.ec2.internal:8042/node/containerlogs/container_1612113777859_0002_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n",
      "Cleaned up endpoint http://ec2-54-91-225-25.compute-1.amazonaws.com:8998/\n"
     ]
    }
   ],
   "source": [
    "%manage_spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "df = spark.read.csv(\"s3://jolfr-capstone3/clean/mem-features.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import BooleanType, DoubleType\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import pandas as pd\n",
    "\n",
    "dfl = df\n",
    "\n",
    "bool_cols = [f.name for f in df.schema.fields if isinstance(f.dataType, BooleanType)]\n",
    "\n",
    "for column in bool_cols:\n",
    "    dfl = df.withColumn(column, col(column).cast(DoubleType()))\n",
    "    \n",
    "dfl = dfl.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
    "\n",
    "cols = [f.name for f in dfl.schema.fields if isinstance(f.dataType, DoubleType)]\n",
    "\n",
    "# convert to vector column first\n",
    "vector_col = \"corr_features\"\n",
    "assembler = VectorAssembler(inputCols=cols, outputCol=vector_col, handleInvalid=\"skip\")\n",
    "df_vector = assembler.transform(dfl).select(vector_col)\n",
    "\n",
    "# get correlation matrix\n",
    "matrix = Correlation.corr(df_vector, vector_col)\n",
    "\n",
    "# get column and row mappings\n",
    "mapper = {}\n",
    "index = 0\n",
    "for col in cols:\n",
    "    mapper[index] = col\n",
    "    index += 1\n",
    "\n",
    "# reshape and add metadata    \n",
    "corr = matrix.collect()[0][\"pearson({})\".format(vector_col)].values.reshape(len(cols),len(cols))\n",
    "corr = pd.DataFrame(corr).rename(mapper, axis=0).rename(mapper, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Top Features\n",
    "The top 50 features will be selected based upon highest correlation to the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "corr = corr.sort_values(by=['label'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MEAN(transactions-price_difference WHERE is_auto_renew = 0)', 'SUM(transactions-planned_daily_price WHERE is_auto_renew = 0)', 'PERCENT_TRUE(transactions-WEEKEND(transaction_date) WHERE is_auto_renew = 0)', 'PERCENT_TRUE(transactions-WEEKEND(membership_expire_date) WHERE is_auto_renew = 0)', 'NUM_UNIQUE(transactions-DAY(membership_expire_date))', 'MIN(transactions-price_difference)', 'TOTAL_PREVIOUS_MONTH(transactions-price_difference, transaction_date)', 'MODE(transactions-MONTH(membership_expire_date))', 'STD(transactions-planned_daily_price)', 'MEAN(transactions-price_difference WHERE is_cancel = 0)', 'MODE(transactions-MONTH(transaction_date))', 'LAST(transactions-price_difference)', 'AVG_TIME_BETWEEN(transactions-transaction_date)', 'NUM_UNIQUE(transactions-payment_method_id)', 'STD(transactions-daily_price)', 'MAX(transactions-planned_daily_price)', 'LAST(transactions-planned_daily_price)', 'PERCENT_TRUE(logs-WEEKEND(date))', 'MEAN(transactions-planned_daily_price WHERE is_auto_renew = 1)', 'SUM(transactions-actual_amount_paid WHERE is_auto_renew = 0)']"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "features = [] # stores column names\n",
    "\n",
    "features_count = 20 # number of features to gather\n",
    "threshold = 0.90 # threshold to ignore collinear columns\n",
    "\n",
    "for index, row in corr.iterrows():\n",
    "    # exits loop once enough features are gathered\n",
    "    if(len(features) == features_count):\n",
    "        break;\n",
    "    if(index != 'label'):\n",
    "        collinear = False\n",
    "        for feature in features:\n",
    "            if(corr[index][feature] > threshold):\n",
    "                collinear = True\n",
    "                break;\n",
    "        if(collinear == False):\n",
    "            features.append(index)\n",
    "features    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Dataset using Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "cols = [\"msno\", \"time\", \"label\"]\n",
    "cols = cols + features\n",
    "\n",
    "df = df.select(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "df.write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").mode('overwrite').save('s3://jolfr-capstone3/clean/features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
