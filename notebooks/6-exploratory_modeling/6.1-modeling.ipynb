{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 Exploratory Modeling\n",
    "\n",
    "##### Description\n",
    "\n",
    "Pipelines to train the models are implemented in this notebook. The preprocessing steps of scaling and encoding are embedded in the pipeline. The exploratory models are trained to determine which has the highest accuracy score.\n",
    "\n",
    "##### Notebook Steps\n",
    "\n",
    "1. Connect Spark\n",
    "1. Input data\n",
    "1. Basic data review\n",
    "1. Visualize relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connect Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sparkmagic.magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163f2f9801644066b45a8c16b7a0a138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MagicsControllerWidget(children=(Tab(children=(ManageSessionWidget(children=(HTML(value='<br/>'), HTML(value='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added endpoint http://ec2-54-221-79-184.compute-1.amazonaws.com:8998/\n",
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1</td><td>application_1611312942316_0002</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-30-130.ec2.internal:20888/proxy/application_1611312942316_0002/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-24-133.ec2.internal:8042/node/containerlogs/container_1611312942316_0002_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\thoma\\anaconda3\\envs\\capstone-03\\lib\\site-packages\\sparkmagic\\livyclientlib\\livysession.py\", line 54, in run\n",
      "    self.livy_session.refresh_status_and_info()\n",
      "  File \"C:\\Users\\thoma\\anaconda3\\envs\\capstone-03\\lib\\site-packages\\sparkmagic\\livyclientlib\\livysession.py\", line 287, in refresh_status_and_info\n",
      "    response = self._http_client.get_session(self.id)\n",
      "  File \"C:\\Users\\thoma\\anaconda3\\envs\\capstone-03\\lib\\site-packages\\sparkmagic\\livyclientlib\\livyreliablehttpclient.py\", line 39, in get_session\n",
      "    return self._http_client.get(self._session_url(session_id), [200]).json()\n",
      "  File \"C:\\Users\\thoma\\anaconda3\\envs\\capstone-03\\lib\\site-packages\\sparkmagic\\livyclientlib\\reliablehttpclient.py\", line 34, in get\n",
      "    return self._send_request(relative_url, accepted_status_codes, self._session.get)\n",
      "  File \"C:\\Users\\thoma\\anaconda3\\envs\\capstone-03\\lib\\site-packages\\sparkmagic\\livyclientlib\\reliablehttpclient.py\", line 45, in _send_request\n",
      "    return self._send_request_helper(self.compose_url(relative_url), accepted_status_codes, function, data, 0)\n",
      "  File \"C:\\Users\\thoma\\anaconda3\\envs\\capstone-03\\lib\\site-packages\\sparkmagic\\livyclientlib\\reliablehttpclient.py\", line 76, in _send_request_helper\n",
      "    raise HttpClientException(u\"Invalid status code '{}' from {} with error payload: {}\"\n",
      "sparkmagic.livyclientlib.exceptions.HttpClientException: Invalid status code '404' from http://ec2-54-221-79-184.compute-1.amazonaws.com:8998/sessions/2 with error payload: {\"msg\":\"Session '2' not found.\"}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\thoma\\anaconda3\\envs\\capstone-03\\lib\\threading.py\", line 950, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\thoma\\anaconda3\\envs\\capstone-03\\lib\\site-packages\\sparkmagic\\livyclientlib\\livysession.py\", line 61, in run\n",
      "    self.livy_session.logger.error(u'{}'.format(e))\n",
      "AttributeError: 'NoneType' object has no attribute 'logger'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned up endpoint http://ec2-54-221-79-184.compute-1.amazonaws.com:8998/\n"
     ]
    }
   ],
   "source": [
    "%manage_spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "There are two seperate datasets we will be working with while modeling. They are train.csv and validate.csv. Train is used to train the model, while validate is used to perform evaluation on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "train = spark.read.csv(\"s3://jolfr-capstone3/training/train.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Define Pipeline\n",
    "\n",
    " 1. Feature Hasher\n",
    " 1. Standard Scaler\n",
    " 1. Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import GBTClassifier, RandomForestClassifier, DecisionTreeClassifier\n",
    "from pyspark.ml.feature import FeatureHasher, StandardScaler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Collects column names for later use in pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "cols = train.drop(\"label\").columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Feature Hasher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "hasher = FeatureHasher(inputCols=cols, outputCol=\"hash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "scaler = StandardScaler(inputCol=hasher.getOutputCol(), outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "pipe = Pipeline(stages=[hasher, scaler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Define Paramter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Define Cross Validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "lr_pipe = Pipeline(stages=[pipe, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cdbedbe15824fe9a3566f4cdb108f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-29-6b1c1eb6ec7e>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mget_ipython\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun_cell_magic\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'spark'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m''\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'lr_pipe.fit(train)\\n'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\envs\\capstone-03\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001B[0m in \u001B[0;36mrun_cell_magic\u001B[1;34m(self, magic_name, line, cell)\u001B[0m\n\u001B[0;32m   2380\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbuiltin_trap\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2381\u001B[0m                 \u001B[0margs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mmagic_arg_s\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcell\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2382\u001B[1;33m                 \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2383\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2384\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<decorator-gen-119>\u001B[0m in \u001B[0;36mspark\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\capstone-03\\lib\\site-packages\\IPython\\core\\magic.py\u001B[0m in \u001B[0;36m<lambda>\u001B[1;34m(f, *a, **k)\u001B[0m\n\u001B[0;32m    185\u001B[0m     \u001B[1;31m# but it's overkill for just that one bit of state.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    186\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mmagic_deco\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 187\u001B[1;33m         \u001B[0mcall\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mlambda\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    188\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    189\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcallable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\capstone-03\\lib\\site-packages\\sparkmagic\\livyclientlib\\exceptions.py\u001B[0m in \u001B[0;36mwrapped\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     72\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mwrapped\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     73\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 74\u001B[1;33m             \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     75\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mexceptions_to_handle\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     76\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mconf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mall_errors_are_fatal\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\capstone-03\\lib\\site-packages\\sparkmagic\\magics\\remotesparkmagics.py\u001B[0m in \u001B[0;36mspark\u001B[1;34m(self, line, cell, local_ns)\u001B[0m\n\u001B[0;32m    171\u001B[0m             \u001B[0mcoerce\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_coerce_value\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcoerce\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    172\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcontext\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0mCONTEXT_NAME_SPARK\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 173\u001B[1;33m                 return self.execute_spark(cell, args.output, args.samplemethod,\n\u001B[0m\u001B[0;32m    174\u001B[0m                                           args.maxrows, args.samplefraction, args.session, coerce)\n\u001B[0;32m    175\u001B[0m             \u001B[1;32melif\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcontext\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0mCONTEXT_NAME_SQL\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\capstone-03\\lib\\site-packages\\sparkmagic\\magics\\sparkmagicsbase.py\u001B[0m in \u001B[0;36mexecute_spark\u001B[1;34m(self, cell, output_var, samplemethod, maxrows, samplefraction, session_name, coerce)\u001B[0m\n\u001B[0;32m     79\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     80\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mexecute_spark\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcell\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutput_var\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msamplemethod\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmaxrows\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msamplefraction\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msession_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcoerce\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 81\u001B[1;33m         \u001B[1;33m(\u001B[0m\u001B[0msuccess\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmimetype\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mspark_controller\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun_command\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mCommand\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcell\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msession_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     82\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0msuccess\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     83\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mconf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshutdown_session_on_spark_statement_errors\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\capstone-03\\lib\\site-packages\\sparkmagic\\livyclientlib\\sparkcontroller.py\u001B[0m in \u001B[0;36mrun_command\u001B[1;34m(self, command, client_name)\u001B[0m\n\u001B[0;32m     38\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mrun_command\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcommand\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mclient_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     39\u001B[0m         \u001B[0msession_to_use\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_session_by_name_or_default\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclient_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 40\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mcommand\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexecute\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msession_to_use\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     41\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     42\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mrun_sqlquery\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msqlquery\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mclient_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\capstone-03\\lib\\site-packages\\sparkmagic\\livyclientlib\\command.py\u001B[0m in \u001B[0;36mexecute\u001B[1;34m(self, session)\u001B[0m\n\u001B[0;32m     42\u001B[0m             \u001B[0mresponse\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msession\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhttp_client\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpost_statement\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msession\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mid\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m             \u001B[0mstatement_id\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mresponse\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34mu'id'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 44\u001B[1;33m             \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_statement_output\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msession\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstatement_id\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     45\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m             self._spark_events.emit_statement_execution_end_event(session.guid, session.kind, session.id,\n",
      "\u001B[1;32m~\\anaconda3\\envs\\capstone-03\\lib\\site-packages\\sparkmagic\\livyclientlib\\command.py\u001B[0m in \u001B[0;36m_get_statement_output\u001B[1;34m(self, session, statement_id)\u001B[0m\n\u001B[0;32m     74\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mstatus\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mFINAL_STATEMENT_STATUS\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     75\u001B[0m                 \u001B[0mprogress\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalue\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstatement\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'progress'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0.0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 76\u001B[1;33m                 \u001B[0msession\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mretries\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     77\u001B[0m                 \u001B[0mretries\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     78\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\capstone-03\\lib\\site-packages\\sparkmagic\\livyclientlib\\livysession.py\u001B[0m in \u001B[0;36msleep\u001B[1;34m(self, retries)\u001B[0m\n\u001B[0;32m    280\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    281\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0msleep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretries\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 282\u001B[1;33m         \u001B[0msleep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_policy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mseconds_to_sleep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mretries\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    283\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    284\u001B[0m     \u001B[1;31m# This function will refresh the status and get the logs in a single call.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "lr_pipe.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## 9. Save Best Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gbt_model = gbt_cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rf_model = rf_cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dt_model = dt_cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gbt = gbt_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rf = rf_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dt = dt_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = dt_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "gbt = GBTClassifier()\n",
    "\n",
    "gbt_pipeline = Pipeline(stages=[one-hot, scaler, gbt])\n",
    "\n",
    "gbt_cv = CrossValidator(estimator=pipeline,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_pipeline = Pipeline(stages=[one-hot, scaler, rf])\n",
    "\n",
    "rf_cv = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "dt_pipeline = Pipeline(stages=[one-hot, scaler, dt])\n",
    "\n",
    "dt_cv = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_model = gbt_cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = rf_cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = dt_cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = gbt_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = rf_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = dt_model.transform(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}